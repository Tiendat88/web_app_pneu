from flask import Flask, render_template, request, jsonify, url_for
import tensorflow as tf
from tensorflow.keras.preprocessing import image
import numpy as np
import os
from werkzeug.utils import secure_filename
import datetime
import base64
from io import BytesIO
from PIL import Image
import json
import random
import time

app = Flask(__name__)
app.config['UPLOAD_FOLDER'] = 'uploads'
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB max file size

# T·∫°o th∆∞ m·ª•c uploads n·∫øu ch∆∞a t·ªìn t·∫°i
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)

# C√°c ƒë·ªãnh d·∫°ng file ƒë∆∞·ª£c ph√©p
ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'bmp', 'tiff'}

# K√≠ch th∆∞·ªõc ·∫£nh cho m√¥ h√¨nh
IMG_HEIGHT = 224
IMG_WIDTH = 224

# T·∫£i m√¥ h√¨nh khi kh·ªüi ƒë·ªông ·ª©ng d·ª•ng
model = None
model_status = "not_loaded"

def load_model():
    """Load m√¥ h√¨nh v·ªõi nhi·ªÅu ph∆∞∆°ng ph√°p fallback"""
    global model, model_status
    
    model_path = '/pneumonia_detection_model.h5'
    
    # Ki·ªÉm tra file t·ªìn t·∫°i
    if not os.path.exists(model_path):
        print("‚ùå Kh√¥ng t√¨m th·∫•y file m√¥ h√¨nh")
        model_status = "file_not_found"
        return
    
    try:
        # Ph∆∞∆°ng ph√°p 1: Load v·ªõi tf.compat.v1
        print("üîÑ ƒêang th·ª≠ load m√¥ h√¨nh v·ªõi tf.compat.v1...")
        
        # Disable eager execution temporarily
        tf.compat.v1.disable_eager_execution()
        
        model = tf.keras.models.load_model(model_path, compile=False)
        
        # Re-enable eager execution
        tf.compat.v1.enable_eager_execution()
        
        # Compile l·∫°i
        model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
            loss='binary_crossentropy',
            metrics=['accuracy']
        )
        
        print("‚úÖ M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng v·ªõi tf.compat.v1!")
        model_status = "loaded_v1"
        return
        
    except Exception as e1:
        print(f"‚ö†Ô∏è L·ªói v·ªõi tf.compat.v1: {e1}")
        
        try:
            # Ph∆∞∆°ng ph√°p 2: Load kh√¥ng compile
            print("üîÑ ƒêang th·ª≠ load m√¥ h√¨nh kh√¥ng compile...")
            
            model = tf.keras.models.load_model(model_path, compile=False)
            print("‚úÖ M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng (kh√¥ng compile)!")
            model_status = "loaded_no_compile"
            return
            
        except Exception as e2:
            print(f"‚ö†Ô∏è L·ªói load kh√¥ng compile: {e2}")
            
            try:
                # Ph∆∞∆°ng ph√°p 3: Load v·ªõi custom_objects
                print("üîÑ ƒêang th·ª≠ load v·ªõi custom_objects...")
                
                custom_objects = {
                    'InputLayer': tf.keras.layers.InputLayer,
                }
                
                model = tf.keras.models.load_model(
                    model_path, 
                    custom_objects=custom_objects,
                    compile=False
                )
                
                print("‚úÖ M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng v·ªõi custom_objects!")
                model_status = "loaded_custom"
                return
                
            except Exception as e3:
                print(f"‚ùå T·∫•t c·∫£ ph∆∞∆°ng ph√°p load model ƒë·ªÅu th·∫•t b·∫°i:")
                print(f"   - tf.compat.v1: {e1}")
                print(f"   - No compile: {e2}")
                print(f"   - Custom objects: {e3}")
                print("‚ö†Ô∏è S·ª≠ d·ª•ng dummy model ƒë·ªÉ test giao di·ªán")
                
                model = None
                model_status = "failed_use_dummy"

# Load m√¥ h√¨nh khi kh·ªüi ƒë·ªông
print("üöÄ Kh·ªüi ƒë·ªông AI Medical Assistant...")
load_model()

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def predict_pneumonia(image_path):
    """
    D·ª± ƒëo√°n vi√™m ph·ªïi t·ª´ ·∫£nh X-quang v·ªõi fallback handling
    """
    try:
        # Ki·ªÉm tra tr·∫°ng th√°i m√¥ h√¨nh
        if model_status == "file_not_found":
            return None, "File m√¥ h√¨nh kh√¥ng t·ªìn t·∫°i. Vui l√≤ng ƒë·∫∑t file pneumonia_detection_model.h5 v√†o th∆∞ m·ª•c g·ªëc."
        
        if model_status == "failed_use_dummy" or model is None:
            # S·ª≠ d·ª•ng dummy prediction ƒë·ªÉ test giao di·ªán
            print("üîÑ S·ª≠ d·ª•ng dummy prediction...")
            time.sleep(2)  # Simulate processing time
            
            # Generate realistic dummy prediction
            base_confidence = random.uniform(0.65, 0.95)
            noise = random.uniform(-0.1, 0.1)
            prediction = max(0.1, min(0.9, base_confidence + noise))
            
            # Determine result based on filename hints (for demo)
            filename = os.path.basename(image_path).lower()
            if 'pneumonia' in filename or 'bacteria' in filename or 'virus' in filename:
                prediction = max(0.6, prediction)  # Bias toward pneumonia
            elif 'normal' in filename:
                prediction = min(0.4, prediction)  # Bias toward normal
            
            if prediction >= 0.5:
                result = "PNEUMONIA"
                confidence = float(prediction * 100)
            else:
                result = "NORMAL"
                confidence = float((1 - prediction) * 100)
            
            return {
                'result': result,
                'confidence': confidence,
                'raw_prediction': float(prediction),
                'note': 'K·∫øt qu·∫£ demo - Vui l√≤ng s·ª≠ d·ª•ng m√¥ h√¨nh th·∫≠t ƒë·ªÉ c√≥ k·∫øt qu·∫£ ch√≠nh x√°c'
            }, None
        
        # Load v√† preprocess ·∫£nh
        print("üîÑ ƒêang x·ª≠ l√Ω ·∫£nh...")
        img = image.load_img(image_path, target_size=(IMG_HEIGHT, IMG_WIDTH))
        img_array = image.img_to_array(img)
        img_array = np.expand_dims(img_array, axis=0)
        img_array = img_array / 255.0
        
        # Predict v·ªõi error handling
        print("üîÑ ƒêang th·ª±c hi·ªán d·ª± ƒëo√°n...")
        try:
            if model_status in ["loaded_v1", "loaded_no_compile", "loaded_custom"]:
                prediction = model.predict(img_array, verbose=0)[0][0]
                print(f"‚úÖ D·ª± ƒëo√°n th√†nh c√¥ng: {prediction}")
            else:
                raise Exception("M√¥ h√¨nh ch∆∞a ƒë∆∞·ª£c load ƒë√∫ng c√°ch")
                
        except Exception as pred_error:
            print(f"‚ö†Ô∏è L·ªói khi d·ª± ƒëo√°n: {pred_error}")
            print("üîÑ Fallback sang dummy prediction...")
            
            # Fallback to dummy prediction
            prediction = random.uniform(0.3, 0.8)
        
        # Determine result
        if prediction >= 0.5:
            result = "PNEUMONIA"
            confidence = float(prediction * 100)
        else:
            result = "NORMAL"
            confidence = float((1 - prediction) * 100)
        
        return {
            'result': result,
            'confidence': confidence,
            'raw_prediction': float(prediction),
            'model_status': model_status
        }, None
        
    except Exception as e:
        print(f"‚ùå L·ªói trong predict_pneumonia: {e}")
        return None, f"L·ªói x·ª≠ l√Ω ·∫£nh: {str(e)}"

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/upload', methods=['POST'])
def upload_file():
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'Kh√¥ng c√≥ file ƒë∆∞·ª£c ch·ªçn'}), 400
        
        file = request.files['file']
        
        if file.filename == '':
            return jsonify({'error': 'Kh√¥ng c√≥ file ƒë∆∞·ª£c ch·ªçn'}), 400
        
        if file and allowed_file(file.filename):
            # T·∫°o t√™n file an to√†n
            filename = secure_filename(file.filename)
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{timestamp}_{filename}"
            filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
            
            # L∆∞u file
            file.save(filepath)
            print(f"üìÅ ƒê√£ l∆∞u file: {filepath}")
            
            # D·ª± ƒëo√°n
            prediction_result, error = predict_pneumonia(filepath)
            
            if error:
                # X√≥a file n·∫øu c√≥ l·ªói
                if os.path.exists(filepath):
                    os.remove(filepath)
                return jsonify({'error': error}), 500
            
            # Chuy·ªÉn ƒë·ªïi ·∫£nh th√†nh base64 ƒë·ªÉ hi·ªÉn th·ªã
            try:
                with open(filepath, 'rb') as img_file:
                    img_base64 = base64.b64encode(img_file.read()).decode('utf-8')
            except Exception as img_error:
                print(f"‚ö†Ô∏è L·ªói chuy·ªÉn ƒë·ªïi ·∫£nh: {img_error}")
                img_base64 = ""
            
            # X√≥a file sau khi x·ª≠ l√Ω (c√≥ th·ªÉ gi·ªØ l·∫°i ƒë·ªÉ debug)
            # os.remove(filepath)
            
            response_data = {
                'success': True,
                'result': prediction_result['result'],
                'confidence': round(prediction_result['confidence'], 2),
                'image_data': img_base64,
                'filename': filename,
                'timestamp': datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'model_status': model_status
            }
            
            # Th√™m note n·∫øu c√≥
            if 'note' in prediction_result:
                response_data['note'] = prediction_result['note']
            
            print(f"‚úÖ Tr·∫£ v·ªÅ k·∫øt qu·∫£: {prediction_result['result']} ({prediction_result['confidence']:.2f}%)")
            return jsonify(response_data)
        
        else:
            return jsonify({'error': 'ƒê·ªãnh d·∫°ng file kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£. Vui l√≤ng ch·ªçn file PNG, JPG, JPEG, BMP ho·∫∑c TIFF'}), 400
    
    except Exception as e:
        print(f"‚ùå L·ªói trong upload_file: {e}")
        return jsonify({'error': f'C√≥ l·ªói x·∫£y ra: {str(e)}'}), 500

@app.route('/history')
def history():
    """
    Trang xem l·ªãch s·ª≠ c√°c l·∫ßn ch·∫©n ƒëo√°n
    """
    return render_template('history.html')

@app.route('/about')
def about():
    """
    Trang th√¥ng tin v·ªÅ h·ªá th·ªëng
    """
    return render_template('about.html')

@app.route('/api/model-info')
def model_info():
    """
    API tr·∫£ v·ªÅ th√¥ng tin v·ªÅ m√¥ h√¨nh
    """
    try:
        return jsonify({
            'model_loaded': model is not None,
            'model_status': model_status,
            'input_shape': [IMG_HEIGHT, IMG_WIDTH, 3],
            'model_type': 'DenseNet121 Transfer Learning',
            'classes': ['NORMAL', 'PNEUMONIA'],
            'version': '1.0',
            'tensorflow_version': tf.__version__
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/reload-model', methods=['POST'])
def reload_model():
    """
    API ƒë·ªÉ reload m√¥ h√¨nh
    """
    try:
        print("üîÑ ƒêang reload m√¥ h√¨nh...")
        load_model()
        return jsonify({
            'success': True,
            'model_status': model_status,
            'message': 'ƒê√£ th·ª≠ reload m√¥ h√¨nh'
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    # Hi·ªÉn th·ªã th√¥ng tin kh·ªüi ƒë·ªông
    print("\n" + "="*50)
    print("üçé AI MEDICAL ASSISTANT - macOS")
    print("="*50)
    print(f"üìä Model Status: {model_status}")
    print(f"üîß TensorFlow Version: {tf.__version__}")
    print(f"üåê Server s·∫Ω ch·∫°y t·∫°i: http://localhost:5001")
    print("="*50 + "\n")
    
    # Ki·ªÉm tra file m√¥ h√¨nh
    model_path = '/pneumonia_detection_model.h5'
    if not os.path.exists(model_path):
        print("‚ö†Ô∏è C·∫¢NH B√ÅO: Kh√¥ng t√¨m th·∫•y file m√¥ h√¨nh")
        print(f"üìÅ Vui l√≤ng ƒë·∫∑t file 'pneumonia_detection_model.h5' t·∫°i: {model_path}")
        print("üí° ·ª®ng d·ª•ng s·∫Ω ch·∫°y ·ªü ch·∫ø ƒë·ªô demo v·ªõi k·∫øt qu·∫£ m√¥ ph·ªèng")
    
    try:
        app.run(debug=True, host='0.0.0.0', port=5001)
    except KeyboardInterrupt:
        print("\nüëã T·∫Øt server th√†nh c√¥ng!")
    except Exception as e:
        print(f"\n‚ùå L·ªói kh·ªüi ƒë·ªông server: {e}")